# Model Documentation

## v230820

**Sumaries**
ChatGPT gpt-3.5-turbo-0301

**Tags**
ChatGPT gpt-3.5-turbo-0613

**Pre-processing for BERTopic**
`all_businesses_and_tags_230703.RData`
`all_businesses_and_clean_tags_230703.RData`
`all_businesses_and_summaries.RData`

**Cutoff** 03_post_process_BERT.R
```
# Multiple topics per Business Item ---------------------------------------------------------------

top_topics <- topic_probs %>%
  select(index, top_3_topics, prob_1, prob_2, prob_3) %>% 
  separate(top_3_topics, into = c("topic_1", "topic_2", "topic_3"), sep = ",") %>%
  mutate_at(vars(topic_1:topic_3), ~as.integer(sub("V", "", .))) %>% 
  # Re-align topic numbers with topic number generated in BERTopic (topic nr 1 -> topic nr 0)
  mutate(topic_1 = topic_1 - 1) %>% mutate(topic_2 = topic_2 - 1) %>% mutate(topic_3 = topic_3 - 1) %>% 
  mutate(topic_2 = case_when(prob_2 < 0.001 ~ NA,
                             prob_2 >= 0.001 ~ topic_2)) %>% 
  mutate(topic_3 = case_when(is.na(topic_2) == TRUE ~ NA,
                             is.na(topic_2) == FALSE ~ topic_3)) %>% 
  mutate(prob_2 = case_when(prob_2 < 0.001 ~ NA,
                             prob_2 >= 0.001 ~ prob_2)) %>% 
  mutate(prob_3 = case_when(is.na(prob_2) == TRUE ~ NA,
                             is.na(prob_2) == FALSE ~ prob_3))
```

**BERTopic Modelling**
```
# https://maartengr.github.io/BERTopic/getting_started/parameter%20tuning/parametertuning.html#hdbscan
hdbscan_model = HDBSCAN(
    min_cluster_size = 2,
    min_samples = 1,
    metric = 'euclidean',
    prediction_data = True)

# BERTopic German model
# Parameter tuning: https://maartengr.github.io/BERTopic/getting_started/parameter%20tuning/parametertuning.html#bertopic
topic_model = BERTopic(
    language = "multilingual",
    min_topic_size = 2,
    verbose = True,
    top_n_words = 10,
    n_gram_range = (1, 3),
    hdbscan_model = hdbscan_model,
    calculate_probabilities = True,
     # https://www.sbert.net/docs/pretrained_models.html
    embedding_model = "paraphrase-multilingual-mpnet-base-v2").fit(docs, y = categories) # perform supervised topic modeling, we simply use all categories
```

**Topic Names**
- Generated using “Representation” (top_n_words?) produced by BERTopic

Automated Document Intrusion Detection
[1] "Accuracy:  0.731"
[1] "Precision (Mean over all Topics):  0.693"
[1] "Recall (Mean over all Topics):  0.81"
[1] "F1 Score (Mean over all Topics):  0.747"